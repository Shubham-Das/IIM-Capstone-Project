{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImgClassificationReupdate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-y0Kglsxpdx",
        "outputId": "3c4dd90c-1441-4dd1-bb75-5b00ce51709e"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irjixvWLxulw",
        "outputId": "397ca415-34ae-4bfe-e098-e358df4e9a91"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 30 09:34:49 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMhcFaBKyIy_"
      },
      "source": [
        "import os\n",
        "import numpy as np # Csv study\n",
        "import pandas as pd # Dataframe and CSV Study\n",
        "import matplotlib.pyplot as plt # Visualize the images\n",
        "import matplotlib.image as mpimg # Same as above\n",
        "import seaborn as sns # Visualizing the data in plots\n",
        "import cv2 # Image Handeling\n",
        "\n",
        "# For preprocessing and model building\n",
        "import keras # Model/Architecture Building\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPnJKL5Dyn5b"
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbGX2-bUyLen",
        "outputId": "e358bfe1-c26e-4285-df4b-b8fc4bca61ed"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/'\n",
        "os.listdir(path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Book report.gslides',\n",
              " 'NAPAYJ0.html.gdoc',\n",
              " 'IMG_1994 (2).JPG',\n",
              " 'IMG_1995 (1).JPG',\n",
              " 'IMG_1996 (2).JPG',\n",
              " 'IMG_1997 (2).JPG',\n",
              " 'IMG_1998 (2).JPG',\n",
              " 'IMG_2001 (2).JPG',\n",
              " 'IMG_2002 (1).JPG',\n",
              " 'IMG_2003 (2).JPG',\n",
              " 'IMG_2004 (2).JPG',\n",
              " 'IMG_2005 (2).JPG',\n",
              " 'IMG_1996 (1).JPG',\n",
              " 'IMG_1994 (1).JPG',\n",
              " 'IMG_1997 (1).JPG',\n",
              " 'IMG_1998 (1).JPG',\n",
              " 'IMG_2001 (1).JPG',\n",
              " 'IMG_2003 (1).JPG',\n",
              " 'IMG_2004 (1).JPG',\n",
              " 'IMG_2005 (1).JPG',\n",
              " 'IMG_2006 (1).JPG',\n",
              " 'IMG_2010 (1).JPG',\n",
              " 'IMG_2007.JPG',\n",
              " 'IMG_2015 (1).JPG',\n",
              " 'IMG_2016.JPG',\n",
              " 'IMG_2037.JPG',\n",
              " 'IMG_2038 (1).JPG',\n",
              " 'IMG_2039 (1).JPG',\n",
              " 'IMG_2041.JPG',\n",
              " 'IMG_2043 (1).JPG',\n",
              " 'IMG_2044 (1).JPG',\n",
              " 'IMG_2046 (1).JPG',\n",
              " 'IMG_2051.JPG',\n",
              " 'IMG_2004.JPG',\n",
              " 'IMG_2003.JPG',\n",
              " 'IMG_2015.JPG',\n",
              " 'IMG_2005.JPG',\n",
              " 'IMG_2046.JPG',\n",
              " 'IMG_1994.JPG',\n",
              " 'IMG_1998.JPG',\n",
              " 'IMG_2049.JPG',\n",
              " 'IMG_2000.JPG',\n",
              " 'IMG_2044.JPG',\n",
              " 'IMG_2001.JPG',\n",
              " 'IMG_2048.JPG',\n",
              " 'IMG_2010.JPG',\n",
              " 'IMG_2053.JPG',\n",
              " 'IMG_2039.JPG',\n",
              " 'IMG_1997.JPG',\n",
              " 'IMG_2002.JPG',\n",
              " 'IMG_1995.JPG',\n",
              " 'IMG_1996.JPG',\n",
              " 'IMG_2017.JPG',\n",
              " 'IMG_2038.JPG',\n",
              " 'IMG_2006.JPG',\n",
              " 'IMG_2045.JPG',\n",
              " 'IMG_2043.JPG',\n",
              " 'IMG_2292.JPG',\n",
              " 'IMG_2288.JPG',\n",
              " 'IMG_2289.JPG',\n",
              " 'IMG_2287.JPG',\n",
              " 'IMG_2304.JPG',\n",
              " 'IMG_2305.JPG',\n",
              " 'IMG_2303.JPG',\n",
              " 'IMG_2295.JPG',\n",
              " 'IMG_2291.JPG',\n",
              " 'IMG_2306.JPG',\n",
              " 'Drawing4.vsd',\n",
              " 'playfair.gdoc',\n",
              " 'Project proposal (1).gdoc',\n",
              " 'Project proposal.gdoc',\n",
              " 'Software development proposal.gdoc',\n",
              " 'pdf-to-word (1).gdoc',\n",
              " 'Lucidchart',\n",
              " 'IAS DOC (Recovered).gdoc',\n",
              " 'IAS DOC.pdf',\n",
              " 'IAS DOC (1).gdoc',\n",
              " 'A_Students_Attendance_System_Using_QR_Code.pdf',\n",
              " 'QR BASED ATTENDANCE SYSTEM.pdf',\n",
              " 'HOSP_ERD.vsd',\n",
              " 'ASS6.txt',\n",
              " 'IAS DOC.gdoc',\n",
              " 'Colab Notebooks',\n",
              " 'fer2013.tar.gz',\n",
              " 'report_android (1).rtf.gdoc',\n",
              " 'report_android.rtf.gdoc',\n",
              " 'WhatsApp Chat with Shubham (3).gdoc',\n",
              " 'WhatsApp Chat with Shubham (2).gdoc',\n",
              " 'WhatsApp Chat with Shubham (1).gdoc',\n",
              " 'shuvayan_cv.gdoc',\n",
              " 'ContentAMS-Solution.gdoc',\n",
              " 'Travel Reservation September 30 for GOUTAMMR DAS.pdf',\n",
              " 'Other Charges, September 30 for SUBHASISMR KONAR.pdf',\n",
              " 'embedded_imp_ques_ans.pdf',\n",
              " 'Untitled Diagram.drawio',\n",
              " 'QAS',\n",
              " 'Classroom',\n",
              " 'B.Tech_EVEN_Sem_2020_13.12.2019 (1).xlsx',\n",
              " 'SOP_Zoom-Faculty Handout_v4.pdf',\n",
              " 'saddle (1).gdoc',\n",
              " 'mixed strategy.txt',\n",
              " 'saddle.gdoc',\n",
              " 'WhatsApp Chat with Shubham.gdoc',\n",
              " 'IMG-20200420-WA0004.jpg',\n",
              " 'Employee shift schedule.gsheet',\n",
              " 'Explore example.gsheet',\n",
              " 'Project timeline.gsheet',\n",
              " 'Gantt chart.gsheet',\n",
              " 'Monthly budget.gsheet',\n",
              " 'PYTHON 1 CERTIFICATE.pdf',\n",
              " 'EduRate_projected_balance_sheet.xlsx',\n",
              " 'EduRate_projected_balance_sheet (1).gsheet',\n",
              " 'EduRate_projected_balance_sheet.gsheet',\n",
              " 'Balance-Sheet-Template.gsheet',\n",
              " 'Untitled spreadsheet (1).gsheet',\n",
              " 'LAB EXAM SCHEDULE MID JUNE 2020.xlsx',\n",
              " 'LAB EXAM SCHEDULE END JULY 2020.xlsx',\n",
              " 'To-do list (1).gsheet',\n",
              " 'To-do list.gsheet',\n",
              " 'Untitled spreadsheet.gsheet',\n",
              " 'FINAL VID.rar',\n",
              " 'OralHygieneAwareness(FINAL).avi',\n",
              " 'Video.rar',\n",
              " 'Video.tar',\n",
              " 'How you can help Free Tutorials Team.gdoc',\n",
              " 'CAS_31072020_70162853_1502335.pdf',\n",
              " 'Shubham Das_Offer Letter-  SIGNED.pdf',\n",
              " 'VD-1598036915.pdf',\n",
              " 'data.gdoc',\n",
              " 'Amrita Project Work.rar',\n",
              " 'Integrated Program of Business Analytics (IPBA6) - Schedule (1).pdf',\n",
              " 'Integrated Program of Business Analytics (IPBA6) - Schedule.pdf',\n",
              " 'Google Earth',\n",
              " 'train.csv',\n",
              " 'fashion.zip',\n",
              " 'doo-uaqw-jiv - Oct 3, 2020.gjam',\n",
              " 'dataManipulation.gdoc',\n",
              " 'Amrita endo docs.rar',\n",
              " 'TB & Files.rar',\n",
              " 'Amrita Docs.rar',\n",
              " 'WhatsApp Chat with \\u202a+91 97691 08951\\u202c.gdoc',\n",
              " 'IMG-20200905-WA0029.jpg',\n",
              " 'IMG-20200905-WA0019.jpg',\n",
              " 'IMG-20200905-WA0020.jpg',\n",
              " 'Project1',\n",
              " 'fashion',\n",
              " 'fashiong',\n",
              " '.ipynb_checkpoints',\n",
              " 'fashionT',\n",
              " '21996.1.210529-1541.co_release_CLIENT_CONSUMER_x64FRE_en-us.iso',\n",
              " 'Copy of 21996.1.210529-1541.co_release_CLIENT_CONSUMER_x64FRE_en-us.iso',\n",
              " 'Copy of Copy of 21996.1.210529-1541.co_release_CLIENT_CONSUMER_x64FRE_en-us.iso',\n",
              " 'Download',\n",
              " 'CancerDetection',\n",
              " 'AM_Research_Group',\n",
              " 'Project2',\n",
              " 'Project']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2lfiTYiyXri"
      },
      "source": [
        "train = path + '/train.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gls57HpxyzzN",
        "outputId": "1638eac8-b120-49f0-e277-b7e80d5bb7d0"
      },
      "source": [
        "# Reading .csv file\n",
        "train_df = pd.read_csv(path + '/train.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>files</th>\n",
              "      <th>target</th>\n",
              "      <th>images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>../input/fashiondata/data/shoes/5da81ceb7861c2...</td>\n",
              "      <td>shoes</td>\n",
              "      <td>5da81ceb7861c2af6a5a89a7_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>../input/fashiondata/data/beauty/5da81d8a7861c...</td>\n",
              "      <td>beauty</td>\n",
              "      <td>5da81d8a7861c2af6a5a901c_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>../input/fashiondata/data/beauty/5da820f26504f...</td>\n",
              "      <td>beauty</td>\n",
              "      <td>5da820f26504fb65da0043e6_0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>../input/fashiondata/data/jewelry and watches/...</td>\n",
              "      <td>jewelry and watches</td>\n",
              "      <td>5da81c026504fb65cea700d2_0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>../input/fashiondata/data/bags/5da81d2c7861c2a...</td>\n",
              "      <td>bags</td>\n",
              "      <td>5da81d2c7861c2af6a5a8c64_2.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               files  ...                          images\n",
              "0  ../input/fashiondata/data/shoes/5da81ceb7861c2...  ...  5da81ceb7861c2af6a5a89a7_1.jpg\n",
              "1  ../input/fashiondata/data/beauty/5da81d8a7861c...  ...  5da81d8a7861c2af6a5a901c_3.jpg\n",
              "2  ../input/fashiondata/data/beauty/5da820f26504f...  ...  5da820f26504fb65da0043e6_0.jpg\n",
              "3  ../input/fashiondata/data/jewelry and watches/...  ...  5da81c026504fb65cea700d2_0.jpg\n",
              "4  ../input/fashiondata/data/bags/5da81d2c7861c2a...  ...  5da81d2c7861c2af6a5a8c64_2.jpg\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z25AND_byOhf"
      },
      "source": [
        "#Encoding the labels to convert text labels into integer values\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "train_df['target_code']= label_encoder.fit_transform(train_df['target'])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJg3oWUTyhID",
        "outputId": "1d18f5f1-4335-4368-f887-c378ad223cb0"
      },
      "source": [
        "train_df['target_code']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       3\n",
              "1       1\n",
              "2       1\n",
              "3       2\n",
              "4       0\n",
              "       ..\n",
              "5995    2\n",
              "5996    0\n",
              "5997    0\n",
              "5998    1\n",
              "5999    0\n",
              "Name: target_code, Length: 6000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivdUFqjizksw"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#Generating Image Data with ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwL_GagQzp1b",
        "outputId": "13cd5aae-8fd4-492a-da38-4c5af850479d"
      },
      "source": [
        "#loading the data and labels from train.csv file and passing the fashion images directory\n",
        "train_generator=datagen.flow_from_dataframe(dataframe=train_df,\n",
        "                                            directory=path + '/fashion/',\n",
        "                                            x_col=\"images\", y_col=\"target\",\n",
        "                                            class_mode=\"categorical\",\n",
        "                                            shuffle=False,\n",
        "                                            target_size=(80,80),\n",
        "                                            batch_size=32)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6000 validated image filenames belonging to 4 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VROemW9mz3IL",
        "outputId": "1edc9806-d4d7-4897-ed77-b773aaa87f7b"
      },
      "source": [
        "train_images = np.concatenate([train_generator.next()[0] for i in range(train_generator.__len__())])\n",
        "print(train_images.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6000, 80, 80, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA0WwCD_brvp",
        "outputId": "aed58495-e798-4fe0-bc6a-6ae7fa785847",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(train_images.shape)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6000, 80, 80, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk9XDlh60EGd",
        "outputId": "ab1f64bd-7c97-42b9-d7e0-9b0d208ecef0"
      },
      "source": [
        "train_labels = np.concatenate([train_generator.next()[1] for i in range(train_generator.__len__())])\n",
        "print(train_labels.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJy0p3wFBjWj"
      },
      "source": [
        "#Converting train_labels into a dataframe and adding sparse labels to One-Hot Encoded labels\n",
        "train_labels_df = pd.DataFrame(train_labels)\n",
        "train_labels_df[\"label\"] = train_labels_df.idxmax(1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo5roIVLBT-B",
        "outputId": "e82a83c8-030e-48e5-a71e-9e046d51a1f6"
      },
      "source": [
        "#from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "#model = VGG16(weights='imagenet', include_top = False)\n",
        "#features = model.predict(train_images)\n",
        "#print(features.shape)\n",
        "#print(features)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "(6000, 2, 2, 512)\n",
            "[[[[0.7005776  0.         0.10261267 ... 0.         0.0474245\n",
            "    0.        ]\n",
            "   [1.3670032  0.         0.         ... 0.         0.10709065\n",
            "    0.        ]]\n",
            "\n",
            "  [[1.6682777  0.         0.84606487 ... 0.         0.\n",
            "    0.        ]\n",
            "   [2.15841    0.         0.05654669 ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.38446638 0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.6978521  0.         0.         ... 0.         0.16811416\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.5857967  0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [0.76262105 0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.23779702 0.         0.         ... 0.         0.34221616\n",
            "    0.        ]\n",
            "   [0.         0.         0.         ... 0.         0.51823187\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.56276333 0.         0.         ... 0.         0.16996664\n",
            "    0.        ]\n",
            "   [0.14519966 0.         0.         ... 0.         0.06387228\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.9504736  0.         0.         ... 0.         0.5013702\n",
            "    0.        ]\n",
            "   [1.1239076  0.         0.         ... 0.         0.6099826\n",
            "    0.        ]]\n",
            "\n",
            "  [[1.144649   0.         0.         ... 0.         0.\n",
            "    0.        ]\n",
            "   [1.2805401  0.         0.         ... 0.         0.\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.6931573  0.         0.         ... 0.         0.6441256\n",
            "    0.        ]\n",
            "   [0.43451053 0.         0.         ... 0.         0.8456137\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.7621606  0.         0.         ... 0.         0.33245096\n",
            "    0.        ]\n",
            "   [0.29307622 0.         0.         ... 0.01515975 0.22937897\n",
            "    0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.5538857  0.         0.         ... 0.         0.16598693\n",
            "    0.        ]\n",
            "   [0.5796427  0.         0.         ... 0.         0.65020466\n",
            "    0.        ]]\n",
            "\n",
            "  [[0.47168952 0.         0.         ... 0.         0.02227205\n",
            "    0.        ]\n",
            "   [0.8735917  0.         0.         ... 0.         0.36443567\n",
            "    0.        ]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj96R-bRK7Kb",
        "outputId": "1b48dc7e-9915-4f82-d149-e14ee5e9cd3d"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# Setting up the VGG16 base model\n",
        "img_width, img_height = 80, 80\n",
        "model = VGG16(weights='imagenet',\n",
        "                  include_top=False,\n",
        "                  input_shape=(img_width, img_height, 3))\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "model.summary()\n",
        "features = model.predict(train_images)\n",
        "print(features.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 80, 80, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 80, 80, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 80, 80, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 40, 40, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 40, 40, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 40, 40, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 20, 20, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 20, 20, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 20, 20, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 10, 10, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 10, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "(6000, 2, 2, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlQMOv9pBpn9",
        "outputId": "1edd58c5-da4f-422d-d7f5-835f76678b55"
      },
      "source": [
        "train_labels_df[\"label\"]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       3\n",
              "1       1\n",
              "2       1\n",
              "3       2\n",
              "4       0\n",
              "       ..\n",
              "5995    2\n",
              "5996    0\n",
              "5997    0\n",
              "5998    1\n",
              "5999    0\n",
              "Name: label, Length: 6000, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOtY8x-rBz4m"
      },
      "source": [
        "#flattening the extracted features data to create a dataframe\n",
        "train_features = features.reshape(features.shape[0],-1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa78dlYmB3ya"
      },
      "source": [
        "#creating a dataframe of the extracted features\n",
        "img_df = pd.DataFrame(train_features)\n",
        "img_df[\"label\"] = train_labels_df[\"label\"]   #adding label to the features data"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "gXaxnkCZB_yr",
        "outputId": "e22c297c-c039-416b-b92d-8353a43d04a9"
      },
      "source": [
        "img_df"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2009</th>\n",
              "      <th>2010</th>\n",
              "      <th>2011</th>\n",
              "      <th>2012</th>\n",
              "      <th>2013</th>\n",
              "      <th>2014</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "      <th>2019</th>\n",
              "      <th>2020</th>\n",
              "      <th>2021</th>\n",
              "      <th>2022</th>\n",
              "      <th>2023</th>\n",
              "      <th>2024</th>\n",
              "      <th>2025</th>\n",
              "      <th>2026</th>\n",
              "      <th>2027</th>\n",
              "      <th>2028</th>\n",
              "      <th>2029</th>\n",
              "      <th>2030</th>\n",
              "      <th>2031</th>\n",
              "      <th>2032</th>\n",
              "      <th>2033</th>\n",
              "      <th>2034</th>\n",
              "      <th>2035</th>\n",
              "      <th>2036</th>\n",
              "      <th>2037</th>\n",
              "      <th>2038</th>\n",
              "      <th>2039</th>\n",
              "      <th>2040</th>\n",
              "      <th>2041</th>\n",
              "      <th>2042</th>\n",
              "      <th>2043</th>\n",
              "      <th>2044</th>\n",
              "      <th>2045</th>\n",
              "      <th>2046</th>\n",
              "      <th>2047</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.021385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.661660</td>\n",
              "      <td>0.759806</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.096954</td>\n",
              "      <td>0.427908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490744</td>\n",
              "      <td>1.592741</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.778946</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.335853</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.082435</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.373758</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.760228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.203420</td>\n",
              "      <td>0.368500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.463768</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.455262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.625228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.258656</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.015523</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.390076</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141625</td>\n",
              "      <td>0.788709</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.494545</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.012871</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.864980</td>\n",
              "      <td>0.296408</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.434710</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.535860</td>\n",
              "      <td>0.912020</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.536330</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.313359</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.163326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.152389</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.023262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024226</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.029421</td>\n",
              "      <td>0.811006</td>\n",
              "      <td>0.186531</td>\n",
              "      <td>1.37924</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005949</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.527219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.779351</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.612802</td>\n",
              "      <td>0.096803</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.193021</td>\n",
              "      <td>1.117028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.301038</td>\n",
              "      <td>1.084471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.244399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001858</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.131549</td>\n",
              "      <td>0.292215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.613982</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.937866</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.075740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257971</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.084310</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307941</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.585038</td>\n",
              "      <td>2.355613</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.861408</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005660</td>\n",
              "      <td>1.483713</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.919446</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.384649</td>\n",
              "      <td>0.670507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.241677</td>\n",
              "      <td>0.054818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.251663</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.602541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.278563</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.439003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.851708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497809</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062763</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.664446</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.680864</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.888388</td>\n",
              "      <td>0.795534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.130921</td>\n",
              "      <td>0.498622</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.323511</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5995</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119287</td>\n",
              "      <td>0.285892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.801677</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.060471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.364505</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.656181</td>\n",
              "      <td>1.395210</td>\n",
              "      <td>0.148137</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.142828</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449827</td>\n",
              "      <td>0.423564</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.252035</td>\n",
              "      <td>0.194046</td>\n",
              "      <td>0.048767</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.279819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.917744</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.370404</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028410</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5996</th>\n",
              "      <td>1.136669</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.872615</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.336721</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.022974</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.291499</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.414313</td>\n",
              "      <td>0.249777</td>\n",
              "      <td>0.538049</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.726538</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.318156</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.119038</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.825279</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.324244</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.895584</td>\n",
              "      <td>0.261443</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.775203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.022651</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5997</th>\n",
              "      <td>0.735538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.433785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.545468</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.904318</td>\n",
              "      <td>0.090846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.277982</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.072293</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.032766</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.016935</td>\n",
              "      <td>0.819658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134399</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.095841</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.124100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.103024</td>\n",
              "      <td>0.616958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5998</th>\n",
              "      <td>0.443188</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.954413</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.378577</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.356788</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029987</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.121771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.545485</td>\n",
              "      <td>1.879812</td>\n",
              "      <td>0.367434</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.346905</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739346</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.339654</td>\n",
              "      <td>0.148088</td>\n",
              "      <td>0.919169</td>\n",
              "      <td>1.240068</td>\n",
              "      <td>0.829638</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.334435</td>\n",
              "      <td>0.081638</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217526</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5999</th>\n",
              "      <td>0.523888</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.924067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276678</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.113200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010123</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.635251</td>\n",
              "      <td>0.148263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073519</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.493113</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.610173</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.534524</td>\n",
              "      <td>0.432401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.050366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.374313</td>\n",
              "      <td>0.261907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.313963</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.907114</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.286147</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6000 rows × 2049 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0    1         2    3         4  ...  2044  2045      2046  2047  label\n",
              "0     1.021385  0.0  0.000000  0.0  0.000000  ...   0.0   0.0  0.000000   0.0      3\n",
              "1     0.455262  0.0  0.000000  0.0  0.625228  ...   0.0   0.0  0.000000   0.0      1\n",
              "2     0.313359  0.0  0.000000  0.0  0.163326  ...   0.0   0.0  0.001858   0.0      1\n",
              "3     0.000000  0.0  0.000000  0.0  0.000000  ...   0.0   0.0  0.000000   0.0      2\n",
              "4     0.602541  0.0  0.000000  0.0  0.000000  ...   0.0   0.0  0.000000   0.0      0\n",
              "...        ...  ...       ...  ...       ...  ...   ...   ...       ...   ...    ...\n",
              "5995  0.000000  0.0  0.000000  0.0  0.000000  ...   0.0   0.0  0.028410   0.0      2\n",
              "5996  1.136669  0.0  0.872615  0.0  0.000000  ...   0.0   0.0  0.000000   0.0      0\n",
              "5997  0.735538  0.0  0.000000  0.0  0.000000  ...   0.0   0.0  0.000000   0.0      0\n",
              "5998  0.443188  0.0  0.000000  0.0  0.000000  ...   0.0   0.0  0.217526   0.0      1\n",
              "5999  0.523888  0.0  0.000000  0.0  0.000000  ...   0.0   0.0  0.286147   0.0      0\n",
              "\n",
              "[6000 rows x 2049 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSQ_zLPbCEgH"
      },
      "source": [
        "#X = np.array(img_df)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smARy3aGCQmV",
        "outputId": "e27e7757-5413-4c06-a2d1-bf84ee10d0e2"
      },
      "source": [
        "#X.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 2049)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zaqpDkmPCVNN",
        "outputId": "4df08ef3-50ad-4a84-8b52-970863acbc7e"
      },
      "source": [
        "#y = np.array(img_df.drop(['label'],axis=1))\n",
        "#y.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyWUKKr_PLnT"
      },
      "source": [
        "#Splitting the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,\n",
        "                                                    train_labels,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify = train_labels,\n",
        "                                                    test_size=0.2)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afoluCvOPZCj",
        "outputId": "dbda6bfb-41ea-4b29-920b-4ed506ad2372"
      },
      "source": [
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4800, 2, 2, 512) (1200, 2, 2, 512) (4800, 4) (1200, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0mGbooOChMp"
      },
      "source": [
        "# Randomly separate 10% of the images as our validation set\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.20) "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZISSLCA1Coc2"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(80,80,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(GlobalAveragePooling2D(input_shape=(2,2,512)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4, activation=\"softmax\"))\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycBHojDjCuFQ",
        "outputId": "bb697f50-a055-4efb-bb6b-1dda595392a1"
      },
      "source": [
        "# Summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_124 (Conv2D)          (None, 80, 80, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 80, 80, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 40, 40, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_126 (Conv2D)          (None, 40, 40, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_127 (Conv2D)          (None, 40, 40, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_128 (Conv2D)          (None, 20, 20, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_129 (Conv2D)          (None, 20, 20, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_130 (Conv2D)          (None, 20, 20, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 10, 10, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_131 (Conv2D)          (None, 10, 10, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_132 (Conv2D)          (None, 10, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_133 (Conv2D)          (None, 10, 10, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_49 (MaxPooling (None, 5, 5, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_134 (Conv2D)          (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_135 (Conv2D)          (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_136 (Conv2D)          (None, 5, 5, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_50 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_11  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 4)                 16388     \n",
            "=================================================================\n",
            "Total params: 33,613,636\n",
            "Trainable params: 33,613,636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD951o7fCweH"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUpKScTOHBjx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrqCkb46HBm5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlI7NqIhHBq1"
      },
      "source": [
        "from keras.layers import GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3WnatHCC1Ii",
        "outputId": "23da5f0c-3888-44a9-d333-a51a639a99f4"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "model = Sequential()\n",
        "model.add(GlobalAveragePooling2D(input_shape=(2,2,512)))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "global_average_pooling2d_12  (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 4)                 2052      \n",
            "=================================================================\n",
            "Total params: 2,052\n",
            "Trainable params: 2,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v53a0e6q_h9G"
      },
      "source": [
        "# Compile model\n",
        "from keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5CxEIGc_o6i",
        "outputId": "22d49c0d-f63f-448d-a43d-f067a8471c1c"
      },
      "source": [
        "# Train model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_test, y_test))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 1.0985 - acc: 0.5598 - val_loss: 0.7138 - val_acc: 0.7667\n",
            "Epoch 2/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.6808 - acc: 0.7835 - val_loss: 0.5680 - val_acc: 0.8300\n",
            "Epoch 3/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.5466 - acc: 0.8251 - val_loss: 0.5036 - val_acc: 0.8425\n",
            "Epoch 4/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.4889 - acc: 0.8466 - val_loss: 0.4595 - val_acc: 0.8492\n",
            "Epoch 5/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.4399 - acc: 0.8549 - val_loss: 0.4367 - val_acc: 0.8525\n",
            "Epoch 6/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.4067 - acc: 0.8682 - val_loss: 0.4129 - val_acc: 0.8633\n",
            "Epoch 7/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3997 - acc: 0.8721 - val_loss: 0.3941 - val_acc: 0.8700\n",
            "Epoch 8/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3710 - acc: 0.8807 - val_loss: 0.3812 - val_acc: 0.8750\n",
            "Epoch 9/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3667 - acc: 0.8806 - val_loss: 0.3705 - val_acc: 0.8842\n",
            "Epoch 10/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3353 - acc: 0.8916 - val_loss: 0.3619 - val_acc: 0.8800\n",
            "Epoch 11/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3298 - acc: 0.8966 - val_loss: 0.3529 - val_acc: 0.8833\n",
            "Epoch 12/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3261 - acc: 0.8943 - val_loss: 0.3473 - val_acc: 0.8825\n",
            "Epoch 13/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3162 - acc: 0.8991 - val_loss: 0.3378 - val_acc: 0.8833\n",
            "Epoch 14/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3140 - acc: 0.8985 - val_loss: 0.3349 - val_acc: 0.8875\n",
            "Epoch 15/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3096 - acc: 0.9008 - val_loss: 0.3415 - val_acc: 0.8783\n",
            "Epoch 16/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2972 - acc: 0.9030 - val_loss: 0.3255 - val_acc: 0.8908\n",
            "Epoch 17/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2700 - acc: 0.9138 - val_loss: 0.3242 - val_acc: 0.8867\n",
            "Epoch 18/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.3006 - acc: 0.9043 - val_loss: 0.3162 - val_acc: 0.8900\n",
            "Epoch 19/50\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.2820 - acc: 0.9051 - val_loss: 0.3125 - val_acc: 0.8925\n",
            "Epoch 20/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2702 - acc: 0.9125 - val_loss: 0.3109 - val_acc: 0.8942\n",
            "Epoch 21/50\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.2693 - acc: 0.9105 - val_loss: 0.3067 - val_acc: 0.8925\n",
            "Epoch 22/50\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.2730 - acc: 0.9089 - val_loss: 0.3076 - val_acc: 0.8917\n",
            "Epoch 23/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2599 - acc: 0.9142 - val_loss: 0.3015 - val_acc: 0.8950\n",
            "Epoch 24/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2490 - acc: 0.9229 - val_loss: 0.3005 - val_acc: 0.8900\n",
            "Epoch 25/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2615 - acc: 0.9150 - val_loss: 0.2995 - val_acc: 0.8900\n",
            "Epoch 26/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2405 - acc: 0.9240 - val_loss: 0.2959 - val_acc: 0.8933\n",
            "Epoch 27/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2547 - acc: 0.9224 - val_loss: 0.2997 - val_acc: 0.8908\n",
            "Epoch 28/50\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.2372 - acc: 0.9235 - val_loss: 0.2920 - val_acc: 0.8925\n",
            "Epoch 29/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2511 - acc: 0.9164 - val_loss: 0.2912 - val_acc: 0.8958\n",
            "Epoch 30/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2403 - acc: 0.9241 - val_loss: 0.2891 - val_acc: 0.8925\n",
            "Epoch 31/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2433 - acc: 0.9227 - val_loss: 0.2872 - val_acc: 0.8942\n",
            "Epoch 32/50\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.2345 - acc: 0.9288 - val_loss: 0.2872 - val_acc: 0.8942\n",
            "Epoch 33/50\n",
            "150/150 [==============================] - 0s 2ms/step - loss: 0.2296 - acc: 0.9255 - val_loss: 0.2844 - val_acc: 0.8992\n",
            "Epoch 34/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2217 - acc: 0.9309 - val_loss: 0.2871 - val_acc: 0.8975\n",
            "Epoch 35/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2264 - acc: 0.9246 - val_loss: 0.2819 - val_acc: 0.8992\n",
            "Epoch 36/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2291 - acc: 0.9220 - val_loss: 0.2813 - val_acc: 0.8967\n",
            "Epoch 37/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2234 - acc: 0.9265 - val_loss: 0.2837 - val_acc: 0.8933\n",
            "Epoch 38/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2233 - acc: 0.9231 - val_loss: 0.2809 - val_acc: 0.8950\n",
            "Epoch 39/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2121 - acc: 0.9355 - val_loss: 0.2784 - val_acc: 0.8992\n",
            "Epoch 40/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2189 - acc: 0.9311 - val_loss: 0.2846 - val_acc: 0.8967\n",
            "Epoch 41/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2159 - acc: 0.9273 - val_loss: 0.2770 - val_acc: 0.9033\n",
            "Epoch 42/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2173 - acc: 0.9266 - val_loss: 0.2774 - val_acc: 0.8983\n",
            "Epoch 43/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2137 - acc: 0.9353 - val_loss: 0.2768 - val_acc: 0.8967\n",
            "Epoch 44/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2043 - acc: 0.9352 - val_loss: 0.2752 - val_acc: 0.9000\n",
            "Epoch 45/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2090 - acc: 0.9299 - val_loss: 0.2770 - val_acc: 0.9000\n",
            "Epoch 46/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2127 - acc: 0.9381 - val_loss: 0.2754 - val_acc: 0.8992\n",
            "Epoch 47/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.1948 - acc: 0.9405 - val_loss: 0.2757 - val_acc: 0.8992\n",
            "Epoch 48/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2143 - acc: 0.9334 - val_loss: 0.2762 - val_acc: 0.9042\n",
            "Epoch 49/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.2007 - acc: 0.9354 - val_loss: 0.2765 - val_acc: 0.8983\n",
            "Epoch 50/50\n",
            "150/150 [==============================] - 0s 3ms/step - loss: 0.1957 - acc: 0.9348 - val_loss: 0.2756 - val_acc: 0.8958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "INCKWY_z_q3c",
        "outputId": "89b4faa1-23e2-4ae7-a1a2-f259459bce14"
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWwtPlw7bLoY",
        "outputId": "e9f1302e-e064-417b-d919-df8117cb1e78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate the test set\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Final test %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# evaluate the train set\n",
        "scores = model.evaluate(X_train, y_train, verbose=0)\n",
        "print(\"Final train %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final test acc: 89.58%\n",
            "Final train acc: 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKBnC5hcbeJw"
      },
      "source": [
        "img = image.load_img(path + '/predictImages/' +'prod4.jpg',target_size=(2,2,512))\n",
        "img = image.img_to_array(img)\n",
        "img = img/255"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwgnRYmscFxM",
        "outputId": "71541e90-b8a1-4c1b-f000-c60c2fc7eb44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "classes = np.array(train_df.columns[2:])\n",
        "proba = model.predict(img.reshape(1,2,2,512))\n",
        "among4 = np.argsort(proba[0])[:-5:-1]\n",
        "for i in range(4):\n",
        "    print(\"{}\".format(classes[among4[i]])+\" ({:.3})\".format(proba[0][among4[i]]))\n",
        "plt.imshow(img)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-7f039f8e3175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mamong4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mamong4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" ({:.3})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mamong4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 12 into shape (1,2,2,512)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjxDFeFPcJqT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}